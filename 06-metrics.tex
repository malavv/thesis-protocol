% Objective 1 is to develop a set of quality indicators.

% Q1. How many do you need.
% Q2. How do you assess them
% Q3. How do you make a decision after assessing them.

At the core of the ability of audit and feedback to generate insights and induce change is the quality of its measurement. Performance measurement ``seeks to monitor, evaluate, and communicate the extent to which various aspects of the health system meet their key objectives'' \cite{smith2009performance}. A related question then becomes: ``what are the most suitable quality measures for a given care process and a local context?''. The suitability of quality measures will depend on their alignment with an organizational context, their relevance to the actors, their ability to be attributed to specific actors, and their feasibility, accuracy, and reliability \cite{polanczyk2019quality}.

For this first objective, I aim to identify a set of quality indicators for electronic audit and feedback suitable for assessing and improving the appropriateness of heart failure management in adult patients at the MUHC. This set of indicators will be used for both arm of the RCT in objective 3, and its integration is assessed for usability in objective 2.

\section{Research Design}
The study is a single center retrospective exploratory analysis of clinical data from patients with heart failure treated at the McGill University Health Center. Data on the care of adult patients will be obtained for patients discharge from the ED, the ward, or the ICU with an ICD-9 or ICD-10 diagnosis of heart failure\footnote{From AHA's, Get with the Guidelines\textsuperscript{\textcopyright} - Heart Failure}. Additionally, I will collect data on the treating physician, the patient's last admission, and any re-admissions to the \gls{MUHC}. For this analysis, one year of data will be collected, as has been done in prior studies of \gls{HF} \gls{AF} \cite{kasje2006educational}. Based on the average over the last 5 years at the MUHC, this approach would include data for 1670 patients discharged by 271 physicians.

There are three aspects to my aim of identifying a set of quality indicators. First, the number of indicators included; second, the criteria for evaluating the indicators; and third, the overall criteria for deciding which indicator to include.

For the first question, I am aiming to include approximately 10 indicators, which is similar to the number used in a previous study \cite{matthews2007impact}. There is no clear guidance on the number of indicators in the literature on A\&F, but systems with too few indicators may not contain enough information to engage participants and those with too many may pose a heavy cognitive load resulting in lower usability. For the evaluation of performance indicators, I will use the criteria developed by Campbell (Appendix C for more details)  \cite{campbell2002research} and the characteristics of successful A\&F \cite{ivers2012audit}. Finally, once the attributes of the potential measures are characterised, I will determine the final selection based on a consensus of local substantive experts, my advisors, and myself.

\begin{table}[h!]
\centering
\vspace{-2mm}
\begin{tabular}{c|c}
     \textbf{Campbell's Prerequisites} & \textbf{A\&F Criteria}  \\ 
     \hline
     Acceptability         & Baseline Performance  \\  
     Feasibility           & Availability of Action Plan \\
     Reliability           & Frequency; related to patient load \\
     Sensitivity to change & Latency; time to availability \\
     Predictive value   &  \\
\end{tabular}
\caption{Criteria for the evaluation of quality indicators}
\vspace{-5mm}
\end{table}

\section{Quality Measures}
Multiple efforts have been made between institutions and advocacy groups to define a set of evidence-based, actionable indicators for heart failure \cite{hong2006overview, fonarow2010improving, kelley2006health}. Newer interventions are encouraged to use existing measures instead of developing their own. Doing so accelerates development, contributes to the soundness of the evidence, improves face/content validity, facilitates reproducibility, and promotes the use of measures associated with significant health outcomes \cite{smith2009performance}. 
Candidate measures will be derived from a recent systematic review of quality indicators for the cardiovascular intensive care unit (\gls{ICU}). This list contains 31 \gls{HF} specific and 28 general quality indicators. Example potential indicators include ``length of stay for HF patients'' and ``overall readmission rate'' \cite{goldfarb2018systematic}. Risk adjustment will be performed if needed.

\section{Data and Participants}
Data will be obtained through the MUHC data warehouse. An anonymous ID will be used in place of personal identifiers to minimize the risk of re-identification for patients and care providers in this phase of the research. The data collected for each patient will be drawn from a local adaptation of a recently proposed Lean case report form (\gls{CRF}) for heart failure \cite{psotka2019design}. Validation of a local adaptation of the Lean CRF using data available in the MUHC data warehouse is currently underway. 

Approval from the MUHC research ethics review board will be requested along with a waiver of the need to obtain individual consent from patients and physicians. This dataset and waiver will be reused for objective 2 but not 3. The risk of re-identifying patients and physicians is low due to the use of retrospective, routinely collected anonymized data and the implementation of procedures to store the data securely.

\section{Analysis plan}
The data will be explored using descriptive statistics to present visual and tabular representations of the quality measures along with their completeness and trends over time. Measures will also be stratified by demographic factors, cardiovascular risk, and physician characteristics.

The descriptive statistics will be used to assess the feasibility, presence of valid and reliable data, along with baseline performance possible frequency of update. Stratified analysis will be used to assess the reliability, or how indicators can be reproducibly computed between providers and patients. The same technique is used for sensitivity to change, or the indicator's capacity to detect changes in quality of care. Acceptability is supported by being on the list of candidates, but will also be confirmed by a local expert. Latency will be assessed with DW analysts as the time between an action and presence of data in the system. Availability of an action plan will be checked by going to the original framework of the indicators. Finally, it will be assumed candidate measures have content validity. Predictive value will be assessed only for process indicators, and will be measured as the degree of association between improvement in the indicator and lower HF re-admissions.
% Issues
Potential issues include no indicators being suitable, which is unlikely given the candidate measures are used in similar healthcare systems. Also, there is the potential that the Lean CRF will not be compatible with local data. The local adaptation I propose to use should address this issue.

% 1 - Exclude stays for patients who died during their stay? Since they can't have readmission.
%   - Would mess with mortality estimates, and it's the same for everyone.
% 2 - The final set will be selected by my advisors and I
%   - What?!? What criteria, how?, how is that replicable.
% 3 - How will you process the predictive validity modeling?
%   - Predictive validity will be measured as the degree of association between the measure and lower HF re-admissions and will only be assessed for HF specific process measures.
% 4 - How to you plan on doing risk adjustment?
%   - APR-DRG, is one solution, by weighted average, something like group 1-2-3
% 5 - Will the quality indicators work for ED, ward, AND ICU were people are much sicker?
%   - I would assume the indicators won't be "irrelevant" for lighter context. From there, the intervention is mainly about getting Health professional to improve their own practice. But social aspects will potentially be adjusted for risk, or stratified against comparable colleagues.


% Acceptability                  - (Somewhat confirmed by being on list, but confirmation by local substantive expert)
% Feasibility                    - (from descriptive statistics)
% Reliability                    - (Stratified analysis by provider to look for irregularities in measures)
% Sensitivity                    - (Stratified analysis by patients and trends in time) See if varies
% Validity                       - (Content Validity assessed by org. framework, degree of association between better measure and lower HF readmission for process measure, for outcome measure assumed predictive) 
% Baseline Performance           - (from descriptive statistics)
% Availability of Action Plan    - (Looking at the framework from which the measures come)
% Frequency                      - (from descriptive statistics)
% Latency                        - (Assesses with DW analyst, as the time from action to system knowing)

% Cut out : Any required risk adjustment will be made based on diagnostic related groups (\gls{APR-DRG}).