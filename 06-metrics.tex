% Objective 1 is to develop a set of quality indicators.

% Q1. How many do you need.
% Q2. How do you assess them
% Q3. How do you make a decision after assessing them.

At the core of audit and feedback's ability to generate insights and induce change is the quality of its measurement. Performance measurement "seeks to monitor, evaluate, and communicate the extent to which various aspects of the health system meet their key objectives."\cite{smith2009performance} A related question then becomes: "what are the most suitable quality measures for a given care process and local context?". The suitability of quality measures will depend on their alignment with an organizational context, its relevant to its actors, its attributability to specific actors, its feasibility, accuracy, and reliability.\cite{polanczyk2019quality}

For this first objective, I aim to identify a set of suitable quality indicators for electronic audit and feedback to assess and improve the appropriateness of heart failure management in adult patients at the MUHC. This set of indicators will be used in adapting the system assessed for usability in objective 2, and impact how the effect of the behavioural intervention will be measured in objective 3.

\section{Research Design}
The study is a single center retrospective exploratory analysis of secondary clinical data from patient with heart failure at the McGill University Health Center. Data on the care of adult patients will be obtained if the patients were admitted to the hospital with an ICD-9 or ICD-10 diagnosis of heart failure.\footnote{From AHA's, Get with the Guidelines\textcopyright - Heart Failure} Additionally, I will collect data on the discharge provider, the patient's last admission and any re-admission. For this analysis, 1 year of data will be collected matching prior A\&F HF research\cite{kasje2006educational} and giving a manageable estimate of 600 potential patients\footnote{Based on MUHC DW numbers}.

There are three aspects to my aim of identifying a set of quality indicators. First, how many items should this set contains; second, what are the criteria for the evaluation of indicators; and third, how do you make a decision once you measured all criteria.

To the first question, I aim to get around 10 indicators. There is no real guidance in the literature on A\&F, but too few and the system might not contain enough information to engage participants and too many might lead to overly heavy cognitive load resulting in lower usability. One prior group used a similar number of 9.\cite{matthews2007impact} Next, the evaluation of performance indicators will be driven by criteria from 1) Campbell's prerequisite for quality measures\cite{campbell2002research} and from 2) the characteristics of successful A\&F\cite{ivers2012audit}. Finally, once the attributes of the potential measures are characterised, the final set will be selected by the research committee along with a local substantive expert by consensus.

\begin{center}
    \begin{tabular}{ c|c }
         \textbf{Campbell's Prerequisites} & \textbf{A\&F Criteria}  \\ 
         \hline
         Acceptability & Baseline Performance  \\  
         Feasibility & Availability of Action Plan \\
         Reliability & Frequency; related to patient load \\
         Sensitivity & Latency; time to availability \\
         Validity &  \\
    \end{tabular}
\end{center}

\section{Quality Measures}
Multiple efforts have been made between institutions and advocacy groups to define a set of evidence-based actionable indicators for heart failure.\cite{hong2006overview}\cite{fonarow2010improving} \cite{kelley2006health} At this point, newer intervention are encouraged to use existing list of candidate measures instead of going to the source material. Doing so accelerate development and contributes to the soundness of the evidence, better face/content validity, reproducibility (between institutions), and more evidence on their association with significant health outcomes.\cite{smith2009performance}

For the list of candidate measures, this work will make use of a recent systematic review of quality indicators for the cardiovascular  intensive care unit (\gls{ICU}). This list containes 31 \gls{HF} specific and 28 general quality indicators. Example of quality indicators include "length of stay for HF patients" and "overall readmission rate".\cite{goldfarb2018systematic}

\section{Data and Participants}
Data for the first and second objective of this research will be obtained from the MUHC data warehouse. Anonymous ID will be used to minimize the risk to patients and their care providers. The data collected for each patient will be a local adaptation of a recently proposed Lean case report form (\gls{CRF}) form for heart failure.\cite{psotka2019design} A study is underway to create and validate this local adaptation of the Lean CRF based on what data is available in the MUHC data warehouse for automated collection.

Authorization from the MUHC ethics review board will be requested but no plan are made to require either the patients or the physicians to provide format consent. The risk to patients and physicians is low due to the use of retrospective anonymized data which is the result of normal business records.

\section{Analysis plan}
The data will be explored using descriptive statistics to present visual and tabular representation of the quality measures along with their completeness and trends in time. A stratified representation will be calculated by demographic factors, cardiovascular risk, and general physician characteristics.

The descriptive statistics will be used to assess the feasibility (data is present and is either computer readable or processable), baseline performance (average score among providers), and frequency (average frequency of update). Stratified analysis will be used for the reliability (look at irregularity in measures between providers or patients), and sensitivity (looking at amount of variance between patients and over time). Acceptability is supported by being on the list of candidates, but will also be confirmed by local expert. Latency will be assessed with DW analysts as the time between action and system knowing. Availability of an action plan will be checked by going to the original framework of the indicators. Finally, content validity is assumed satisfied by the original authors and the predictive validity will be measured as the degree of association between the measure and lower HF re-admissions. Predictive validity will only be assessed for HF specific process measures.

Potential issues include no indicators being suitable, which I find unlikely given the candidates are used in similar healthcare systems. Also, the potential of the Lean CRF to not be compatible with local data. The local adaptation I propose to use is studied for this exact eventuality.

% Acceptability                  - (Somewhat confirmed by being on list, but confirmation by local substantive expert)
% Feasibility                    - (from descriptive statistics)
% Reliability                    - (Stratified analysis by provider to look for irregularities in measures)
% Sensitivity                    - (Stratified analysis by patients and trends in time) See if varies
% Validity                       - (Content Validity assessed by org. framework, degree of association between better measure and lower HF readmission for process measure, for outcome measure assumed predictive) 
% Baseline Performance           - (from descriptive statistics)
% Availability of Action Plan    - (Looking at the framework from which the measures come)
% Frequency                      - (from descriptive statistics)
% Latency                        - (Assesses with DW analyst, as the time from action to system knowing)