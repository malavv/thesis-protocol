% Study Limitations and Mitigation
A major challenge in designing this electronic audit and feedback system is, in collaboration with the clinical team, find quality improvements topics which are important for the users, have data and quality standards available, and are appropriate targets for A\&F. This also means having clinical partners which are willing to take time to participate in the governance of this project. These partners are essential when planning an implementation to prevent rejection, lack of trust, or perceived intrusion. Physicians wont be remunerated for their participation, but a request will be made for them to get continuing medical education (CME) credits.

Studying gamification is complicated by the holistic nature of the changes it requires along with the absence of an agree upon single set of components. For this reason, all the necessary modifications will be evaluated as-a-whole and we will follow an explicit framework while reporting our design choices and their effect. A RCT of an unvalidated  intervention could be dangerous, hence objective 2. Given the required difference in design, creating a valid synthetic comparator would be difficult, hence the choice of an existing system. Once the system is complete, future research could decompose the effect of individual elements of our gamified system. Evidence exists pointing to gamified interventions being more fun and marketing could be used to emphasise this aspects and drive adoption. However, both arms will received the same amount and kind of implementation efforts. It is likely the choice of a RCT will prevent us from collecting richer narrative data on the perception users have of the intervention but a more qualitative exploration can still be performed after the trial.

It is difficult to forecast the effect of modifications in adoption and engagement on health related patient outcomes. Yet, since current evidence points to \gls{AF} being effective, broader and more engaged use should lead to an overall greater effect. For the same reason, it is difficult to put threshold of clinical meaningfulness. Given the nature of the environment, this study is likely under-powered, yet candidates are limited and the need for automated analysis makes a multi-centre study unrealistic.

Also, ongoing quality improvement effort could threaten the generalizability of the estimated effect of the behavioural intervention. However, because of randomization it is unlikely to affect internal validity. Since it has been reported that performance feedback systems could lead to unintended negative effects, summary statistics will be monitored and actions will be discussed by the thesis committee.\cite{terris2009attribution} Support staff will be on hand for both systems, and only severe bugs will be fixed during the trial. Secular trends will be difficult to explore but there should be some variation in participants entry time. Contamination is likely to be present with users viewing or sharing reports from another arm. Since reports are individualized, and the main metrics are adoption and engagement, the effect of contamination is likely to be low.

% Designers are evaluator
% Volunteer bias likely in high performer, which are less likely to improve.
% Mechanism to combat attrition could interact with intervention.